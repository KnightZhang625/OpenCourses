library(MASS)

sample.data <- function(n) {
  rpois(n, lambda = kAlpha * kBeta)
}

log.lik <- function(a, b, Y) {
  # Log-likelihood of the data
  sum(dpois(Y, lambda=a*b, log=T))
}

log.prior <- function(a, b) {
  # No prior for this model (could use something like an Expo -- see below)
  #return(0)
  # return(dexp(a, rate=10, log=T))
  return (-log(a*b))
}

log.posterior <- function(a, b, Y) {
  log.lik(a, b, Y) + log.prior(a, b)
}

mle <- function(y) {
  # Example code to compute the MLE given the data
  # Note: The model y ~ Pois(a * b) is misspecified so there are
  #   multiple MLEs.
  #
  # Args:
  #   y = vector of values (generated by sample.data)
  # Example:
  #   y = sample.data(100)
  #   mle(y)
  f <- function(par) {
    log.lik(par[1], par[2], y)
  }
  x = optim(par=c(0.2,0.6), fn=f, control=list(fnscale=-1),
            method="L-BFGS-B", lower=c(1e-3, 1e-3))
  print(sprintf("Log-likelihood=%.3f", x$value))
  return(x$par)
}


plot.posterior.density <- function(data) {
  # Plots the density of the posterior density with contour lines.
  #
  # Args:
  #   data = vector of values (generated by sample.data)
  # Example:
  #   y = sample.data(100)
  #   explore.posterior.density(y)
  a = seq(.1, kBound, length.out=400)
  b = a
  gr = expand.grid(x=a, y=b)
  z = apply(gr, 1, function(par) log.lik(par[1], par[2], data))
  z = matrix(z, nrow=length(a), ncol=length(b))
  print("Summay of likelihood values.")
  print(summary(as.vector(z)))
  print("log-likelihood of the true parameter values")
  print(log.lik(kAlpha, kBeta, data))
  z0 = quantile(z, probs = c(0.1))
  z1 = max(z)
  ncols = 10000
  cols = topo.colors(ncols)
  i = apply(gr, 1, function(par) {
    ll = log.posterior(par[1], par[2], data)
    if(ll < z0) return(0)
    return((ll - z0) / (z1 - z0))
  })
  par(mfrow=c(1, 1))
  # hist(i)
  j = ncols * i
  j[j==0] <- 1
  plot(gr[,1], gr[,2], xlab="a", ylab="b", col=cols[j], pch=".", cex=4)
  contour(a, b, z, nlevels = 50, add=T, cex=2, col="black")
  points(c(kAlpha), c(kBeta), pch="x", cex=2.5)
  lines(a, kAlpha * kBeta / a, col="red")
}

explore.log.lik <- function(data, ndraws=1e4) {
  # Simply tries random values for (a, b) and computes the likelihood.
  #
  random.par <- function() {
    return(runif(2, min=1e-4, max=20))
  }
  mPar = t(replicate(ndraws, { random.par() }))
  z = apply(mPar, 1, function(row) log.lik(row[1], row[2], data))
  mPar = cbind(mPar, z)
  # order by increasing likelihood
  mPar = mPar[rev(order(z)), ]
}

rgamma.trunc <- function(upper.bound, s, r) {
  # Sample from truncated gamma.
  # TODO: Find a better implementation.
  x <- upper.bound + 10
  while(x > upper.bound) {
    x = rgamma(1, shape=s, rate=r)
  }
  return(x)
}

my.rgamma.trunc <- function(n,upper.bound, s, r) {
  # Sample from truncated gamma.
  # TODO: Find a better implementation.
  result=c()
  for(i in 1:n){
    x <- upper.bound + 10
    while(x > upper.bound) {
      x = rgamma(1, shape=s, rate=r)
    }
    result[i]=x
  }
  return(result)
}



plot.chain <- function(mcmc.chain) {
  mcmc.niters = nrow(mcmc.chain)
  burnin = 0.1 * mcmc.niters
  mcmc.chain = mcmc.chain[burnin:mcmc.niters, ]
  f = kde2d(x=mcmc.chain[, 1], y=mcmc.chain[, 2], n=100)
  image(f, xlim=c(quantile(mcmc.chain[, 1],probs=c(0.02,0.98))), ylim=c(quantile(mcmc.chain[, 2],probs=c(0.02,0.98))))
}

mcmc.gibbs <- function(y, mcmc.niters=1e4) {
  # Runs Gibbs on the data y
  S = sum(y)  # sufficient statistic
  n = length(y)
  
  mcmc.chain <- matrix(3, nrow=mcmc.niters, ncol=2)
  
  for(i in 2:mcmc.niters) {
    beta.last <- mcmc.chain[i-1, 2]
    # Conditionals are truncated gammas.
    alpha <- rgamma.trunc(kBound, s=S+1, r=n * beta.last)
    beta <- rgamma.trunc(kBound, s=S+1,  r=n * alpha)
    mcmc.chain[i, ] <- c(alpha, beta)
  }
  # Plot empirical density
  plot.chain(mcmc.chain)
  return(mcmc.chain)
}

mcmc.mh <- function(y, mcmc.niters=1e5) {
  # Complete with MH.
  S = sum(y)
  n = length(y)
  mcmc.chain <- matrix(0.1, nrow=mcmc.niters, ncol=2)
  nacc <- 0
  for(i in 2:mcmc.niters) {
    mu <- rgamma.trunc(kBound**2, s=S+1, r=n)
    
    # 1. Current state
    alpha.old = mcmc.chain[i-1, 1]
    beta.old = mcmc.chain[i-1, 2]
    # 2. Propose new state
    #   Respect symmetry in (a,b)
    #alpha.new = runif(1, min=mu/kBound, max=kBound)
    #Alpha=2 Beta=5 Mode=1/5 mean=2/7
    #alpha.new =mu/beta.old+rbeta(1,5,5)-1/2
    alpha.new=rbeta(1,6,6)
    #alpha.new =rnorm(1,(mu/beta.old),0.09)
    #Alpha=2 Beta=2 Mode=1/2 mean=1/2
    #alpha.new=mu/beta.old+rbeta(1,10,10)-1/2
    #alpha.new=rbeta(1,2,2)
    beta.new = mu / alpha.new
    #mu=alpha*beta
    # if(runif(1) < 0.5) {
    #  beta.new = alpha.new
    # alpha.new = mu / beta.new
    #}
    # 3. Ratio
    mh.ratio = min(0, log.posterior(alpha.new, beta.new, y) -
                     log.posterior(alpha.old, beta.old, y))
    #log(dbeta(alpha.old,5,5))-
    #log(dbeta(alpha.new,5,5))
    
    if(runif(1) < exp(mh.ratio)) {
      # Accept
      mcmc.chain[i, ] <- c(alpha.new, beta.new)
      nacc <- nacc + 1
    } else {
      mcmc.chain[i, ] <- c(alpha.old, beta.old)
    }
  }
  # Cut the burnin period.
  print(sprintf("Acceptance ratio %.2f%%", 100 * nacc / mcmc.niters))
  plot.chain(mcmc.chain)
  return(mcmc.chain)
}

kBound = 10
kAlpha = 5
kBeta = 4

# Source data.
waterbuck <- read.table("data/waterbuck.txt", head=T, stringsAsFactors=F)[,1]
impala <- read.table("data/impala.txt", head=T, stringsAsFactors=F)[,1]

# need to lower the acceptance ratio
chain <- list()
for (i in 1:10) {
  kBound <- 100
  chain$waterbuck[[i]] <- mcmc.mh(waterbuck)
  kBound <- 50
  chain$impala[[i]] <- mcmc.mh(impala)
